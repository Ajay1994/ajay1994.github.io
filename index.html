<!DOCTYPE html>
<html>
    <head>
        <title>Ajay Jaiswal's Homepage</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <!-- UIkit CSS -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/uikit@3.3.1/dist/css/uikit.min.css" />

        <!-- UIkit JS -->
        <script src="https://cdn.jsdelivr.net/npm/uikit@3.3.1/dist/js/uikit.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/uikit@3.3.1/dist/js/uikit-icons.min.js"></script>

        <style>
            .uk-label{
                color: black;
                text-transform: none;
                background-color: transparent;
                border: 1px solid black;
                padding: 0px 3px;
            }
	    .news{
		    border: 1px solid black;
		    width: 90%;
		    height: 250px;
		    overflow-x: auto;
		    overflow-y: auto;
		    border-color: #e5e5e5;
		    padding: 10px;
		    background-color: #fff;
		    border-radius: 4mm;
	    }
	    .uk-text-bold {
		    font-weight: 600;
		}
	    .uk-h2, h2 {
		    font-size: 1.5rem;
		}
	    .uk-text-lead {
		    font-size: 1.0rem;
		    line-height: 1.5;
		    color: #333;
		}
	   .uk-text-lead {
		    font-size: 1.0rem;
		    line-height: 1.5;
		    color: #094d1f;
		}
        </style>
    </head>
    <body style="background-color: #FFFFFF">
        <nav class="uk-navbar-container uk-margin uk-light" style="background-color: #BF5701" uk-navbar>
            <div class="uk-navbar-left">
                <a class="uk-navbar-item uk-logo uk-text-primary" href="index.html">Ajay Jaiswal's Homepage</a>
            </div>
            <div class="uk-navbar-right">
                <ul class="uk-navbar-nav">
                    <li class="uk-active uk-visible@m"> <a href="index.html"> Home </a> </li>
                    <li class="uk-active uk-visible@m"> <a href="index.html#research"> Research </a> </li>
                    <li class="uk-active uk-visible@m"> <a href="resources.html"> Resources </a> </li>
                    <li class="uk-active uk-visible@m"> <a href="index.html#contact"> Contact </a> </li>
                    <li class="uk-active uk-visible@m"> <a href="index.html#bio"> About </a> </li>
                    <a class="uk-active uk-navbar-toggle uk-hidden@m" uk-navbar-toggle-icon href="#offcanvas-nav-primary" uk-toggle></a>
                </ul>
            </div>
        </nav>

        <div id="offcanvas-nav-primary" uk-offcanvas="overlay: true">
            <div class="uk-offcanvas-bar uk-flex uk-flex-column">
                <ul class="uk-nav uk-nav-primary uk-nav-center uk-margin-auto-vertical">
                    <li class="uk-active"> <a href="index.html"> Home </a> </li>
                    <li class="uk-active"> <a href="index.html#research"> Projects </a> </li>
                    <li class="uk-active"> <a href="resources.html"> Resources </a> </li>
                    <li class="uk-active"> <a href="index.html#contact"> Contact </a> </li>
                    <li class="uk-active"> <a href="index.html#bio"> About </a> </li>
                </ul>
            </div>
        </div>

        <!-- Header -->
        <!-- <div class="uk-section uk-flex uk-flex-center uk-section-secondary uk-light"> -->
        <div class="uk-flex uk-flex-center">
            <div class="uk-container uk-width-1-1 uk-width-3-4@m uk-padding-small" uk-grid>
            <!-- <div class="uk-container uk-container-large uk-flex-middle uk-padding-small" uk-grid> -->
                <a class="uk-flex uk-flex-center uk-width-1-1 uk-width-auto@m" href="#">
                    <div class="uk-width-1-3 uk-width-small@s uk-visible@l">
                        <img class="uk-border-circle uk-responsive-height uk-responsive-width" src="new_dp.jpeg" alt="Portrait" />
                    </div>
                </a>
                <div class="uk-width-expand uk-margin-remove">
                    <p class="uk-h1 uk-text-center uk-text-left@m uk-width-expand@m uk-margin-remove">
                        Ajay Jaiswal
                    </p>
                    <p>
                        I am a Ph.D. student at the 
			<a href = "https://www.ischool.utexas.edu/" style="color:#800000">
			The University of Texas at Austin</a> working with
			<b><a href = "https://yingding.ischool.utexas.edu/" style="color:#800000">Prof. Ying Ding</a></b>, and 
			<b><a href = "https://www.ece.utexas.edu/people/faculty/atlas-wang" style="color:#800000">Prof. Atlas Wang</b>.</a> I am a member of 
			<b>Visual Informatics Group
			<a href = "https://vita-group.github.io/" style="color:#800000">(VITA)</a> @UT Austin</b>. I am also a recipient of 
			<a href = "https://cockrell.utexas.edu/news/archive/9708-amazon-awards-1st-research-prizes-through-science-hub" style="color:#800000">Amazon Ph.D. Fellowship</a>.
                        My reseach interest are empirical foundations of machine learning: using rigorous controlled experiments to understand the impact of data, model architecture, 
			and other components of a pipeline to enable efficient and reliable machine learning systems. During my PhD, I applied this to address several fundamental 
			bottlenecks (efficient and scalable training, fine-tuning and inference) for modern-day neural networks (especially large foundational models and graph neural networks). 
			My research accomplishments are evidenced by several impactful publications in top-tier venues, e.g., NeurIPS, ICML, ICLR, ECCV, ICCV, etc. In the past, I have interned at Apple AIML, Amazon Search, and Adobe Research.
                    </p>
		    <p>
			    Prior to joining UT Austin, I was a Graduate Student in Computer Science at 
					<a href = "http://www.iitkgp.ac.in/" style="color:#800000">Indian Institute of Technology, Kharagpur</a>. 
					I was advised by 
					<a href = "https://cse.iitkgp.ac.in/~animeshm/" style="color:#800000">Prof. Animesh Mukherjee</a> and 
					<a href = "https://cse.iitkgp.ac.in/~pawang/" style="color:#800000">Prof. Pawan Goyal</a> at the CNeRG Lab. 
			    		I have also spent 3 wonderful years as Lead Research Engineer 
					at Advanced Technology Lab, Samsung Electronics, India under the supervision of
					<a href="https://scholar.google.com/citations?hl=en&user=E6Gasu0AAAAJ&view_op=list_works&sortby=pubdate" style="color:#800000">Dr. Vijay Narayan Tiwari</a>.
	            </p>
                    <!-- Buttons for desktop device -->
                    <div class="uk-margin-horizontal uk-visible@m">
                        <a href="#contact" class="uk-button uk-button-default uk-margin-small-right"> Mail </a>
                        <a href="https://scholar.google.com/citations?user=I783HxYAAAAJ&hl=en" class="uk-button uk-button-default uk-margin-small-right">Scholar </a>
                        <a href="https://github.com/Ajay1994" class="uk-button uk-button-default uk-margin-small-right"> GitHub </a>
			<a href="https://ajay1994.github.io/blog/" class="uk-button uk-button-default uk-margin-small-right"> Blog </a>
                        <a href="https://www.linkedin.com/in/ajay-jaiswal-600a9455/" class="uk-button uk-button-default uk-margin-small-right"> LinkedIn </a>
			<a href="https://utexas.box.com/s/fzjae7ko5z9em7vnsy4lkhuzryhj2m5i" class="uk-button uk-button-default uk-margin-small-right"> Resume/CV </a>
                    </div>
                    <!-- Buttons for mobile device -->
                    <div class="uk-margin-horizontal uk-flex uk-flex-center uk-hidden@m">
                        <a href="#contact" class="uk-button uk-button-default uk-margin-small-right" uk-icon="mail"></a>
                        <a href="https://scholar.google.com/citations?user=I783HxYAAAAJ&hl=en" class="uk-button uk-button-default uk-margin-small-right" uk-icon="google"></a>
                        <a href="https://github.com/Ajay1994" class="uk-button uk-button-default uk-margin-small-right" uk-icon="github"></a>
			<a href="https://ajay1994.github.io/blog/" class="uk-button uk-button-default uk-margin-small-right"> Blog </a>
                        <a href="https://www.linkedin.com/in/ajay-jaiswal-600a9455/" class="uk-button uk-button-default uk-margin-small-right" uk-icon="linkedin"></a>
                    </div>
                </div>
            </div>
        </div>

        <!-- Body -->
        <div class="uk-flex uk-flex-center uk-margin-remove-top uk-margin-medium-bottom">
        <div class="uk-container uk-width-1-1 uk-width-3-4@m uk-padding-small">

            <p id="news" class="uk-h2 uk-text-bold">Recent News</p>
            <ul class="uk-list uk-list-bullet uk-margin-small-bottom news">
		<li>05/2024 5 papers (<a href = "https://arxiv.org/pdf/2310.02277" style="color:#800000">JunkDNA</a>, <a href = "https://arxiv.org/pdf/2403.15447" style="color:#800000">Compressed LLM Trust</a> 
			, <a href = "https://openreview.net/forum?id=OrVl8R13Wy" style="color:#800000">Sparse Cocktail</a>, <a href = "https://arxiv.org/pdf/2310.05175" style="color:#800000">OWL Sparsity</a>
			, <a href = "https://arxiv.org/abs/2402.08170" style="color:#800000">LLM Graph Assistant</a>) accepted to ICML 2024.
		<li>01/2024 One paper (<a href = "https://arxiv.org/abs/2310.01382" style="color:#800000">LLM-KICK</a> || <a href = "https://github.com/VITA-Group/llm-kick" style="color:#800000">[Code]</a>) accepted to ICLR 2024 from internship at Apple.</li>
		<li>07/2023 One paper (<a href = "https://arxiv.org/abs/2306.03805" style="color:#800000">LLM Essential Sparsity</a> || <a href = "https://github.com/VITA-Group/essential_sparsity" style="color:#800000">[Code]</a>) accepted to NeurIPS 2023.</li>
		<li>07/2023 One paper accepted to ICCV 2023.</li>
		<li>05/2023 I joined Apple AI/ML team to work with Yinfei Yang, Zhe Gan, and Xianzhi Du. 
		<li>04/2023 Three papers (2-first authors with one ORAL) accepted to ICML 2023.</li>
		<li>01/2023 Two papers2 accepted to ICLR 2023.</li>
		<li>10/2022 One paper accepted to WACV 2023.</li>
		<li>09/2022 One paper accepted to NeurIPS 2022.</li>
		<li>08/2022 One paper accepted to ICDM 2022.</li>
		<li>07/2022 One paper accepted to ECCV 2022.</li>
		<li>06/2022 Spending Summer 2022 in Adobe Research as Computational Photography/Computer Vision Intern.</li>
                <li>05/2022 One paper accepted to ICML 2022 (Spotlight).</li>
                <li>01/2022 Awarded Professional Development Fellowship by School of Information, UT Austin</li>
		<li>08/2021 One paper accepted to ML4H 2021.</li>
		<li>07/2021 One paper accepted to ICDM 2021.</li>
            </ul>

            <p id="research" class="uk-h2 uk-text-bold">Selected Publication
		    [<b><a href = "https://scholar.google.com/citations?user=I783HxYAAAAJ&hl=en" style="color:#FF4422;">Full List</a></b>]</p>
            (A superscript * denotes equal contribution)
            <ul class="uk-list uk-margin-small-bottom">
		<li>
                    <div class="uk-text-lead">[ORAL] Instant Soup: Cheap Pruning Ensembles in A Single Pass Can Draw Lottery Tickets from Large Models
                    </div>
                    <div> <u>Ajay Jaiswal*</u>, Shiwei Liu, Tianlong Chen, Ying Ding, Atlas Wang </div>
                    <div style="color:#800000"><i>International Conference on Machine Learning (ICML), 2023 </i></div>
                    <div> We propose an efficient way of identifying high quality sparse subnetwoks with cost equivalent to one pass of LTH.</div>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                    <!-- <img src="https://img.shields.io/github/stars/VITA-Group/Deep_GCN_Benchmarking?style=social&logo=github"><img/> -->
                </li>
		<li>
                    <div class="uk-text-lead">Graph Ladling: Shockingly Simple Distributed GNN Training without Intermediate Communication
                    </div>
                    <div> <u>Ajay Jaiswal*</u>, Shiwei Liu, Tianlong Chen, Ying Ding, Atlas Wang </div>
                    <div style="color:#800000"><i>International Conference on Machine Learning (ICML), 2023 </i></div>
                    <div> We propose a model soup strategy for the GNNs to effectively train on large-scale graph data in a divide and conquere paradigm.</div>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                    <!-- <img src="https://img.shields.io/github/stars/VITA-Group/Deep_GCN_Benchmarking?style=social&logo=github"><img/> -->
                </li>
		<li>
                    <div class="uk-text-lead">Outline, Then Details: Syntactically Guided Coarse-To-Fine Code Generation
                    </div>
                    <div> W. Zheng, S. Sharan, <u>A. Jaiswal</u>, K. Wang, Y. Xi, D. Xu, and Z. Wang</div>
                    <div style="color:#800000"><i>International Conference on Learning Representations (ICLR), 2023 </i></div>
                    <div> We propose ChainCoder, a program synthesis language model that generates Python code progressively, i.e. from coarse to fine in multiple passes..</div>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                    <!-- <img src="https://img.shields.io/github/stars/VITA-Group/Deep_GCN_Benchmarking?style=social&logo=github"><img/> -->
                </li>
		<li>
                    <div class="uk-text-lead">
                        Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!
                    </div>
                    <div> Shiwei Liu, Tianlong Chen, Zhenyu Zhang, Xuxi Chen, Tianjin Huang, <u>Ajay Jaiswal</u>, Zhangyang Wang </div>
                    <div style="color:#800000"><i> International Conference on Learning Representations (ICLR), 2023 </i></div>
                    <div> We propose a new plug-and-play MOE training framework, to enable scaling transformers to better accuracy in the full capacity setting without collapse. </div>
                    <a href="https://openreview.net/forum?id=J6F3lLg4Kdp" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="https://openreview.net/forum?id=J6F3lLg4Kdp" target="_blank" class="uk-button uk-button-text">[Code]</a>
                    <!-- <img src="https://img.shields.io/github/stars/VITA-Group/Deep_GCN_Benchmarking?style=social&logo=github"><img/> -->
                </li>
		<li>
                    <div class="uk-text-lead">
                        Attend Who is Weak: Pruning-assisted Medical Image Localization under Sophisticated and Implicit Imbalances
                    </div>
                    <div> <u>Ajay Jaiswal</u>, Tianlong Chen, Justin F Rousseau, Yifan Peng, Ying Ding, Zhangyang Wang </div>
                    <div style="color:#800000"><i> IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2022 </i></div>
                    <div> We propose to use pruning to adaptively identify hard-to-learn (HTL) training samples, and improve pathology localization by attending them explicitly.</div>
                    <a href="https://arxiv.org/abs/2212.02675" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="https://github.com/VITA-Group/TurbNet" target="_blank" class="uk-button uk-button-text">[Code]</a>
                    <!-- <img src="https://img.shields.io/github/stars/VITA-Group/Deep_GCN_Benchmarking?style=social&logo=github"><img/> -->
                </li>
		<li>
                    <div class="uk-text-lead">
                        Old can be Gold: Better Gradient Flow can make Vanilla-GCNs Great Again
                    </div>
                    <div> <u>Ajay Jaiswal*</u>, Peihao Wang*, Tianlong Chen, Justin F. Rousseau, Ying Ding, Atlas Wang </div>
                    <div style="color:#800000"><i> Advances in Neural Information Processing Systems (NeurIPS), 2022 </i></div>
                    <div> We derive a topology-aware isometric initialization and a Dirichlet Energy guided achitectural rewiring technique that boost vanilla-GCNs to be competitive of state-of-the-art.</div>
                    <a href="https://arxiv.org/abs/2210.08122" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="https://github.com/VITA-Group/GradientGCN" target="_blank" class="uk-button uk-button-text">[Code]</a>
                    <!-- <img src="https://img.shields.io/github/stars/VITA-Group/Deep_GCN_Benchmarking?style=social&logo=github"><img/> -->
                </li>
		<li>
                    <div class="uk-text-lead">
                        RoS-KD: A Robust Stochastic Knowledge Distillation Approach for Noisy Medical Imaging
                    </div>
                    <div> <u>Ajay Jaiswal</u>, Kumar Ashutosh, Justin F Rousseau, Yifan Peng, Zhangyang Wang, Ying Ding </div>
                    <div style="color:#800000"><i> IEEE International Conference on Data Mining (ICDM), 2022 </i></div>
                    <div> Our proposed framework RoS-KD learns a smooth, well-informed, and robust student manifold by distilling knowledge from multiple teachers trained on noisy medical imaging datasets.</div>
                    <a href="https://arxiv.org/abs/2210.08388" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="https://github.com/VITA-Group/TurbNet" target="_blank" class="uk-button uk-button-text">[Code]</a>
                    <!-- <img src="https://img.shields.io/github/stars/VITA-Group/Deep_GCN_Benchmarking?style=social&logo=github"><img/> -->
                </li>
		<li>
                    <div class="uk-text-lead">
                        Single Frame Atmospheric Turbulence Mitigation: A Benchmark Study and A New Physics-Inspired Transformer Model
                    </div>
                    <div> Zhiyuan Mao*, <u>Ajay Jaiswal*</u>, Atlas Wang, Stanley Chan </div>
                    <div style="color:#800000"><i> European Conference on Computer Vision (ECCV), 2022 </i></div>
                    <div> We collect and present two new real-world turbulence datasets along with a physics-inspired transformer model for imaging through atmospheric turbulence. </div>
                    <a href="https://arxiv.org/abs/2207.10040" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="https://github.com/VITA-Group/TurbNet" target="_blank" class="uk-button uk-button-text">[Code]</a>
                    <!-- <img src="https://img.shields.io/github/stars/VITA-Group/Deep_GCN_Benchmarking?style=social&logo=github"><img/> -->
                </li>    
		    
                <li>
                    <div class="uk-text-lead">
                        [Spotlight] Training Your Sparse Neural Network Better with Any Mask
                    </div>
                    <div> <u>Ajay Jaiswal</u>, Haoyu Ma, Tianlong Chen, Ying Ding, Ying Ding, Atlas Wang </div>
                    <div style="color:#800000"><i> International Conference on Machine Learning (ICML), 2022 </i></div>
                    <div> We present a sparse subnetwork training toolkit to imporve the training of subnetworks identified by any static pruning methods (SNIP, GRaSP, LTH, SynFlow, Random). </div>
                    <a href="https://arxiv.org/abs/2206.12755" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="https://github.com/VITA-Group/ToST" target="_blank" class="uk-button uk-button-text">[Code]</a>
                    <!-- <img src="https://img.shields.io/github/stars/VITA-Group/Deep_GCN_Benchmarking?style=social&logo=github"><img/> -->
                </li>
		    
		<li>
                    <div class="uk-text-lead">
                        Supervised Contrastive Learning for Cardiopulmonary Disease Classification and Localization in Chest X-rays using Patient Metadata
                    </div>
                    <div> <u>Ajay Jaiswal</u>, Tianhao Li, Cyprian Zander, Yan Han, Justin Rousseau, Yifan Peng, and Ying Ding </div>
                    <div style="color:#800000"><i> IEEE International Conference on Data Mining (ICDM), 2021 </i></div>
                    <div> We present novel augmentation method based on patient metadata and extend self-supervised contrastive learning framework for cardiopulmonary disease classificaton.</div>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                    <!-- <img src="https://img.shields.io/github/stars/VITA-Group/Deep_GCN_Benchmarking?style=social&logo=github"><img/> -->
                </li>
                
		    
		<li>
                    <div class="uk-text-lead">
                        RadBERT-CL: Factually-Aware Contrastive Learning For Radiology Report Classification
                    </div>
                    <div> <u>Ajay Jaiswal</u>, Liyan Tang, Meheli Ghosh, Justin Rousseau, Yifan Peng, and Ying Ding </div>
                    <div style="color:#800000"><i> Machine Learning for Health (ML4H), 2021 </i></div>
                    <div> We present a constastive learning pre-training framework for Bio-BERT on Radiology Report to capture factual critical information. </div>
                    <a href="https://arxiv.org/abs/2110.14787" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                    <!-- <img src="https://img.shields.io/github/stars/VITA-Group/Deep_GCN_Benchmarking?style=social&logo=github"><img/> -->
                </li>
		    
            </ul>

            <p class="uk-h2 uk-text-bold">Teaching & Service</p>
            <ul class="uk-list uk-list-bullet">
                <li>
                    Conference Reviewer of ICME 2022, ICDM 2021, KDD 2022.
		</li>
		<li>
                    Teaching Assistant - OS programming and ML/DS Programming [IIT Kharagpur]
		</li>
            </ul>

            <p id="contact" class="uk-h2 uk-text-bold">Contact</p>
            <div class="uk-child-width-1-2@m" uk-grid>
                <div class="uk-width-large">
                    <div class="uk-card uk-card-default uk-card-hover uk-card-body">
                        <h3 class="uk-card-title">Address</h3>
                        <p>
                            UTA 5.410 <br/>
                            1616 Guadalupe St <br/>
                            Austin, TX  <br/>
                            United States <br/>
                            78712
                        </p>
                    </div>
                </div>
                <div class="uk-width-large">
                    <div class="uk-card uk-card-primary uk-card-hover uk-card-body"  style="background-color: #BF5701">
                        <h3 class="uk-card-title">Email</h3>
                        <p>
                            <b>Academic</b> <br/>
                            ajayjaiswal [at] utexas.edu
                            <br/><br/>
                            <b>Other Use</b> <br/>
                            ajayjaiswalhi [at] gmail.com
                        </p>
                    </div>
                </div>
            </div>

            <p id="bio", class="uk-h2 uk-text-bold">About Me</p>
            <article class="uk-article">
		Born is a small town (Belthara) in Eastern UP, India, I got my hands on a computer first time during my undergraduate freshman year. 
		My journey in computer science began when I was sixteen year old with a fantastic book "Let Us C" by Yashavant Kanetkar. During my career, I have 
		always tried to make best use of resources and smart people around me to learn and grow. I identified my research potential while working with Prof. Animesh 
		Mukherjee in IIT Kharagpur and later spent some wonderful time in Samsung Research after graduating. Currently, with the grace of GOD, I am very previlaged
		to work and supervised by some extremely brilliant minds in <a href = "https://vita-group.github.io/" style="color:#800000">VITA</a> 
		and  <a href = "https://aihealth.ischool.utexas.edu/" style="color:#800000">AI Health </a> @ UT Austin.
                <blockquote cite="#">
                    <p class="uk-margin-small-bottom">Somewhere, something incredible is waiting to be known.</p>
                    <footer><cite>Prof. Carl Sagan</cite></footer>
                </blockquote>
		<a href="https://www.easycounter.com/">
			<img src="https://www.easycounter.com/counter.php?ajayjaiswal23"
			border="0" alt="Free Hit Counters"></a>
			<br><a href="https://www.easycounter.com/">Visitor Counter</a>
            </article>
        </div>
        </div>


        

        <!-- Footer -->
        <div class="uk-section uk-flex uk-flex-center uk-section-secondary uk-height-small" style="background-color: #BF5701">
            <div class="uk-container uk-container-large uk-text-primary">
                <p class="uk-text-small uk-text-center">Copyright &copy; 2022 Ajay Jaiswal. All Rights Reserved.</p>
                <p class="uk-text-small uk-text-center">Powered by <span uk-icon="uikit">UIkit</span></p>
            </div>
        </div>

    </body>
</html>


<!-- 		<div class="blurb" style="font-family: Arial, Helvetica, sans-serif;">
			<div style="width:750px; height:400px;  float:right; margin-top:20px;">
				<p style="font-size:20px;display: inline-block;">I am a Ph.D. student at the 
					<a href = "https://www.ischool.utexas.edu/" style="color:#800000">
					School of Information, UT Austin</a>. I am fortunate to be advised by 
					<b><a href = "https://yingding.ischool.utexas.edu/" style="color:#800000">Prof. Ying Ding</a></b>, and 
					<b><a href = "https://www.ece.utexas.edu/people/faculty/atlas-wang" style="color:#800000">Prof. Atlas Wang</b>.</a> I am a member of 
					<b>Visual Informatics Group
					<a href = "https://vita-group.github.io/" style="color:#800000">(VITA)</a> @UT Austin</b>. 
					My primary research revolves around Multi-Modal Systems, Model Interpretability and Optimization. I am currently working on 
					designing and improving explainability of the
					training recipe for Sparse Neural Networks. I am also developing AI algorithms 
					across computer vision, natural language processing which assists in critical medical decision-making.</p>

				<p style="font-size:20px;display: inline-block;">Prior to joining UT Austin, I completed my Masters in Computer Science from 
					<a href = "http://www.iitkgp.ac.in/" style="color:#800000">Indian Institute of Technology, Kharagpur</a>. 
					I was advised by 
					<a href = "https://cse.iitkgp.ac.in/~animeshm/" style="color:#800000">Prof. Animesh Mukherjee</a> and 
					<a href = "https://cse.iitkgp.ac.in/~pawang/" style="color:#800000">Prof. Pawan Goyal</a> at the CNeRG Lab. I have also worked as Lead Research Engineer 
					at Advanced Technology Lab, Samsung Electronics, India under the supervision of
					<a href="https://scholar.google.com/citations?hl=en&user=E6Gasu0AAAAJ&view_op=list_works&sortby=pubdate" style="color:#800000">Dr. Vijay Narayan Tiwari</a>.</p>
				<p style="font-size:20px;display: inline-block; color:red"><i>Somewhere, something incredible is waiting to be known.</i> ~Prof. Carl Sagan</p>
			</div>
			<img src="/picturedp.PNG" alt="Italian Trulli" style="width:200px;height:200px;">
			<h3>Ajay Jaiswal</h3>
			<p>PhD Student - UT Austin</p>
			<p>School of Information</p>
			<p style="font-size:12px">Office: UTA 5.410, 1616 Guadalupe St</p>
			<ul>
				   <li><a href="mailto:ajayjaiswal@utexas.edu">Email</a></li>
				   <li><a href="https://scholar.google.com/citations?user=I783HxYAAAAJ&hl=en">Google Scholar</a></li>
			</ul>
		</div> 
		<h2 style = "font-size:20px">News Updates</h2>
		<hr/>
		<div style ="font-size:14px; font-family: Arial, Helvetica, sans-serif;">
			<strong>May, 2022</strong> &emsp;Our work - 'Training Your Sparse Neural Network Better with Any Mask' got accpeted at <a href = "https://icml.cc/Conferences/2022/CallForPapers" style="color:#800000">ICML 2022</a>.</br>
			<strong>Feb, 2022</strong> &emsp; Awarded Professoional Development Award by School of Information, UT Austin </br> 
			<strong>Oct, 2021</strong> &emsp;Our work - 'RadBERT-CL: Factually-Aware Contrastive Learning ForRadiology Report Classification' got accpeted at <a href = "https://ml4health.github.io/2021/index.html" style="color:#800000">ML4H 2021</a>.</br>
			<strong>Aug, 2021</strong> &emsp;Our work - 'SCALP - Supervised Contrastive Learning for Cardiopulmonary Disease Classification and Localization in Chest X-rays using Patient Metadata' got accpeted at <a href = "https://icdm2021.auckland.ac.nz/" style="color:#800000">ICDM 2021</a>.</br>
			<strong>JuL, 2021</strong> &emsp;Winner of the <a href = "https://aihealth.ischool.utexas.edu/AIHealthChallenge/index.html" style="color:#800000">AI Health Data Challenge</a> at UT Austin. (First Prize - $1000)</br>
			<strong>Jun, 2021</strong> &emsp;Our work - 'Using Radiomics as Prior Knowledge for Thorax Disease Classification and Localization in Chest X-rays' got accpeted at AMIA 2021.</br>
			<strong>Jun, 2021</strong> &emsp;Started Working as Graduate Research Assistant with <a href = "http://www.katrinerk.com/" style="color:#800000"> Prof. Katrin Erk </a> on Narrative Inference. </br>
			<strong>Mar, 2021</strong> &emsp;Presented our paper "Understanding Parachuting Collaboration" at iConference 2021.</br>
			<strong>Jan, 2021</strong> &emsp;Started PhD in Information Science at University of Texas at Austin</br>
			<strong>Jan, 2021</strong> &emsp;Receipent of Kilgarlin Fellowship ($2,500/semester - 2021 to 2024)</br>
			<strong>Jan, 2021</strong> &emsp;Receipent of William and Margaret Kilgarlin Endowed Scholarship ($54,750 - 2021 to 2022)</br>
			<strong>Dec, 2020</strong> &emsp;Left job at Advanced Technology Lab, Samsung Electronics, Banglore, India.</br>
			<strong>Feb, 2020</strong> &emsp;Our submitted systems ranked 2nd, and 3rd place for Task 4, and 11 at 
						<a href = "https://alt.qcri.org/semeval2020/index.php?id=tasks" style="color:#800000">SemEval 2020</a>.</br>
		</div>
		<h2 style = "font-size:16px">Select Publications (*Equal Contribution)</h2>
		<hr/>
		<div style ="font-size:14px; font-family: Arial, Helvetica, sans-serif;">
			<p><strong>Training Your Sparse Neural Network Better with Any Mask</strong><br/>
			<u>Ajay Jaiswal</u>, Haoyu Ma, Tianlong Chen, Ying Ding, Ying Ding, Atlas Wang<br/>
		        International Conference on Machine Learning (ICML), 2022. 
			</p>
			<p><strong>RadBERT-CL: Factually-Aware Contrastive Learning ForRadiology Report Classification</strong><br/>
			<u>Ajay Jaiswal</u>, Liyan Tang, Meheli Ghosh, Justin Rousseau, Yifan Peng, and Ying Ding<br/>
		        2021 Machine Learning for Health (ML4H 2021)
			</p>
			<p><strong>SCALP - Supervised Contrastive Learning for Cardiopulmonary Disease Classification and Localization in Chest X-rays using Patient Metadata</strong><br/>
			<u>Ajay Jaiswal</u>, Tianhao Li, Cyprian Zander, Yan Han, Justin Rousseau, Yifan Peng, and Ying Ding<br/>
		        2021 21st IEEE International Conference on Data Mining (ICDM 2021)
			</p>
			<p><strong>Using Radiomics as Prior Knowledge for Abnormality Classification and Localization in Chest X-rays</strong><br/>
			Yan Han, Chongyan Chen, Liyan Tang, Mingquan Lin, <u>Ajay Jaiswal</u>, Ying Ding, Yifan Peng<br/>
		        2021 American Medical Informatics Association Annual Symposium 
			</p>
			<p><strong>Understanding Parachuting Collaboration</strong><br/>
			<u>Ajay Jaiswal</u>, Meijun Liu, Ying Ding<br/>
		        2021 Diversity, Divergence, Dialogue: 16th International Conference, iConference 
			</p>
			<p><strong>Ensemble Architecture for Fine-Tuned Propaganda Detection in News Articles</strong><br/>
			Mayank Raj*, <u>Ajay Jaiswal</u>*, RR Rohit, Ankita Gupta, Sudeep Kumar Sahoo, Vertika Srivastava, Yeon Hyang Kim<br/>
			2020 Proceedings of the Fourteenth Workshop on Semantic Evaluation, 1802-1807
			</p>
			<p><strong>Be Reasonable: Exploiting Large-scale Language Models for Commonsense Reasoning</strong><br/>
			Vertika Srivastava, Sudeep Kumar Sahoo, Yeon Hyang Kim, Rohit Rr, Mayank Raj, <u>Ajay Jaiswal</u><br/>
			2020 Proceedings of the Fourteenth Workshop on Semantic Evaluation, 585-593
			</p>
			<p><strong>Understanding the impact of early citers on long-term scientific impact</strong><br/>
			Mayank Singh, <u>Ajay Jaiswal</u>, Priya Shree, Arindam Pal, Animesh Mukherjee, Pawan Goyal<br/>
			2017 ACM/IEEE Joint Conference on Digital Libraries (JCDL)
			</p>
		</div>
 -->
